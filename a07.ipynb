{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f26ac91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'C:\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\python37\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python37\\lib\\site-packages (from nltk) (2024.4.28)\n",
      "Requirement already satisfied: tqdm in c:\\python37\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\python37\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\python37\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarthak\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d933bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e290753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sarthak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sarthak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sarthak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sarthak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e216da",
   "metadata": {},
   "source": [
    "1.  text\n",
    "2. tokenize\n",
    "3. stop words removal\n",
    "4. POS tagging\n",
    "4. stemming\n",
    "5. lemmatization\n",
    "6. tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a0b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_input = 'input.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cfcb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural language processing (NLP) is a field of artificial intelligence concerned with the interaction between computers and humans in natural language. It aims to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful. NLP techniques are used in a wide range of applications, including machine translation, sentiment analysis, information extraction, and text summarization. One of the key challenges in NLP is dealing with the ambiguity and variability of natural language, which can make it difficult for computers to accurately process and understand text. However, recent advances in machine learning and deep learning have led to significant improvements in NLP performance, making it an increasingly important area of research and development.\\n# Machine learning (ML) is a subset of artificial intelligence that focuses on the development of algorithms that can learn from and make predictions or decisions based on data. ML algorithms can be categorized into supervised learning, unsupervised learning, and reinforcement learning, depending on the type of training data and the learning task. Supervised learning involves training a model on labeled data, while unsupervised learning involves training on unlabeled data. Reinforcement learning involves training a model to interact with an environment and learn from feedback. ML techniques have applications in various domains, including image recognition, speech recognition, medical diagnosis, and autonomous vehicles.\\n# Data science is an interdisciplinary field that combines techniques from statistics, computer science, and domain-specific knowledge to extract insights and knowledge from data. It involves various stages of the data lifecycle, including data collection, data cleaning, data analysis, and data visualization. Data scientists use a variety of tools and techniques, such as machine learning, statistical modeling, and data mining, to uncover patterns and trends in data and make data-driven decisions. Data science has applications in numerous industries, including healthcare, finance, marketing, and e-commerce.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(path_of_input)\n",
    "text = file.read()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3406cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36349b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba7a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_corpus = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "194a7c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acbb795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens,stopwords):\n",
    "    tokens_without_stopwords = []\n",
    "    for i in tokens:\n",
    "        if i not in stopwords:\n",
    "            tokens_without_stopwords.append(i)\n",
    "    return tokens_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fad9d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_without_stopwords = remove_stopwords(tokens,stopwords_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c18cffb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural', 'language', 'processing', '(', 'NLP']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_without_stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a14bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagged_tokens = nltk.pos_tag(tokens_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a00bd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN'),\n",
       " ('(', '('),\n",
       " ('NLP', 'NNP')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagged_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b38233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    stem_tokens = []\n",
    "    for i in tokens:\n",
    "        stemmed_token = stemmer.stem(i)\n",
    "        stem_tokens.append(stemmed_token)\n",
    "    return stem_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e077090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_tokens = stem_tokens(tokens_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "789ea67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natur', 'languag', 'process', '(', 'nlp', ')', 'field', 'artifici']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_tokens[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c5cbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tokens(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = []\n",
    "    for i in tokens:\n",
    "        lemmatized_token = lemmatizer.lemmatize(i)\n",
    "        lemmatized_tokens.append(lemmatized_token)\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec325cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_tokens = lemmatize_tokens(tokens_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83e1aa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural', 'language', 'processing', '(', 'NLP', ')', 'field', 'artificial']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_tokens[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde8da85",
   "metadata": {},
   "source": [
    "# IF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "960d0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "documents = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbfafadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural language processing (NLP) is a field of artificial intelligence concerned with the interaction between computers and humans in natural language. It aims to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful. NLP techniques are used in a wide range of applications, including machine translation, sentiment analysis, information extraction, and text summarization. One of the key challenges in NLP is dealing with the ambiguity and variability of natural language, which can make it difficult for computers to accurately process and understand text. However, recent advances in machine learning and deep learning have led to significant improvements in NLP performance, making it an increasingly important area of research and development.',\n",
       " '# Machine learning (ML) is a subset of artificial intelligence that focuses on the development of algorithms that can learn from and make predictions or decisions based on data. ML algorithms can be categorized into supervised learning, unsupervised learning, and reinforcement learning, depending on the type of training data and the learning task. Supervised learning involves training a model on labeled data, while unsupervised learning involves training on unlabeled data. Reinforcement learning involves training a model to interact with an environment and learn from feedback. ML techniques have applications in various domains, including image recognition, speech recognition, medical diagnosis, and autonomous vehicles.',\n",
       " '# Data science is an interdisciplinary field that combines techniques from statistics, computer science, and domain-specific knowledge to extract insights and knowledge from data. It involves various stages of the data lifecycle, including data collection, data cleaning, data analysis, and data visualization. Data scientists use a variety of tools and techniques, such as machine learning, statistical modeling, and data mining, to uncover patterns and trends in data and make data-driven decisions. Data science has applications in numerous industries, including healthcare, finance, marketing, and e-commerce.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54a80048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_tokens(documents):\n",
    "    document_tokens = []\n",
    "    for doc in documents:\n",
    "        tokens = word_tokenize(doc)\n",
    "        document_tokens.append(tokens)\n",
    "    return document_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e15612d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tokens = get_doc_tokens(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "537f0638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  '(',\n",
       "  'NLP',\n",
       "  ')',\n",
       "  'is',\n",
       "  'a',\n",
       "  'field',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'concerned',\n",
       "  'with',\n",
       "  'the',\n",
       "  'interaction',\n",
       "  'between',\n",
       "  'computers',\n",
       "  'and',\n",
       "  'humans',\n",
       "  'in',\n",
       "  'natural',\n",
       "  'language',\n",
       "  '.',\n",
       "  'It',\n",
       "  'aims',\n",
       "  'to',\n",
       "  'enable',\n",
       "  'computers',\n",
       "  'to',\n",
       "  'understand',\n",
       "  ',',\n",
       "  'interpret',\n",
       "  ',',\n",
       "  'and',\n",
       "  'generate',\n",
       "  'human',\n",
       "  'language',\n",
       "  'in',\n",
       "  'a',\n",
       "  'way',\n",
       "  'that',\n",
       "  'is',\n",
       "  'both',\n",
       "  'meaningful',\n",
       "  'and',\n",
       "  'useful',\n",
       "  '.',\n",
       "  'NLP',\n",
       "  'techniques',\n",
       "  'are',\n",
       "  'used',\n",
       "  'in',\n",
       "  'a',\n",
       "  'wide',\n",
       "  'range',\n",
       "  'of',\n",
       "  'applications',\n",
       "  ',',\n",
       "  'including',\n",
       "  'machine',\n",
       "  'translation',\n",
       "  ',',\n",
       "  'sentiment',\n",
       "  'analysis',\n",
       "  ',',\n",
       "  'information',\n",
       "  'extraction',\n",
       "  ',',\n",
       "  'and',\n",
       "  'text',\n",
       "  'summarization',\n",
       "  '.',\n",
       "  'One',\n",
       "  'of',\n",
       "  'the',\n",
       "  'key',\n",
       "  'challenges',\n",
       "  'in',\n",
       "  'NLP',\n",
       "  'is',\n",
       "  'dealing',\n",
       "  'with',\n",
       "  'the',\n",
       "  'ambiguity',\n",
       "  'and',\n",
       "  'variability',\n",
       "  'of',\n",
       "  'natural',\n",
       "  'language',\n",
       "  ',',\n",
       "  'which',\n",
       "  'can',\n",
       "  'make',\n",
       "  'it',\n",
       "  'difficult',\n",
       "  'for',\n",
       "  'computers',\n",
       "  'to',\n",
       "  'accurately',\n",
       "  'process',\n",
       "  'and',\n",
       "  'understand',\n",
       "  'text',\n",
       "  '.',\n",
       "  'However',\n",
       "  ',',\n",
       "  'recent',\n",
       "  'advances',\n",
       "  'in',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'and',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'have',\n",
       "  'led',\n",
       "  'to',\n",
       "  'significant',\n",
       "  'improvements',\n",
       "  'in',\n",
       "  'NLP',\n",
       "  'performance',\n",
       "  ',',\n",
       "  'making',\n",
       "  'it',\n",
       "  'an',\n",
       "  'increasingly',\n",
       "  'important',\n",
       "  'area',\n",
       "  'of',\n",
       "  'research',\n",
       "  'and',\n",
       "  'development',\n",
       "  '.']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_tokens[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f7bb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_from_doc_tokens(document_tokens,stopwords_corpus):\n",
    "    document_tokens_without_stopwords = []\n",
    "    for doc in document_tokens:\n",
    "        doc_without_stopwords = remove_stopwords(doc,stopwords_corpus)\n",
    "        document_tokens_without_stopwords.append(doc_without_stopwords)\n",
    "    return document_tokens_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3da7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tokens_without_stopwords = remove_stopwords_from_doc_tokens(document_tokens,stopwords_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c2d317a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  '(',\n",
       "  'NLP',\n",
       "  ')',\n",
       "  'field',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'concerned',\n",
       "  'interaction',\n",
       "  'computers',\n",
       "  'humans',\n",
       "  'natural',\n",
       "  'language',\n",
       "  '.',\n",
       "  'It',\n",
       "  'aims',\n",
       "  'enable',\n",
       "  'computers',\n",
       "  'understand',\n",
       "  ',',\n",
       "  'interpret',\n",
       "  ',',\n",
       "  'generate',\n",
       "  'human',\n",
       "  'language',\n",
       "  'way',\n",
       "  'meaningful',\n",
       "  'useful',\n",
       "  '.',\n",
       "  'NLP',\n",
       "  'techniques',\n",
       "  'used',\n",
       "  'wide',\n",
       "  'range',\n",
       "  'applications',\n",
       "  ',',\n",
       "  'including',\n",
       "  'machine',\n",
       "  'translation',\n",
       "  ',',\n",
       "  'sentiment',\n",
       "  'analysis',\n",
       "  ',',\n",
       "  'information',\n",
       "  'extraction',\n",
       "  ',',\n",
       "  'text',\n",
       "  'summarization',\n",
       "  '.',\n",
       "  'One',\n",
       "  'key',\n",
       "  'challenges',\n",
       "  'NLP',\n",
       "  'dealing',\n",
       "  'ambiguity',\n",
       "  'variability',\n",
       "  'natural',\n",
       "  'language',\n",
       "  ',',\n",
       "  'make',\n",
       "  'difficult',\n",
       "  'computers',\n",
       "  'accurately',\n",
       "  'process',\n",
       "  'understand',\n",
       "  'text',\n",
       "  '.',\n",
       "  'However',\n",
       "  ',',\n",
       "  'recent',\n",
       "  'advances',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'led',\n",
       "  'significant',\n",
       "  'improvements',\n",
       "  'NLP',\n",
       "  'performance',\n",
       "  ',',\n",
       "  'making',\n",
       "  'increasingly',\n",
       "  'important',\n",
       "  'area',\n",
       "  'research',\n",
       "  'development',\n",
       "  '.'],\n",
       " ['#',\n",
       "  'Machine',\n",
       "  'learning',\n",
       "  '(',\n",
       "  'ML',\n",
       "  ')',\n",
       "  'subset',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'focuses',\n",
       "  'development',\n",
       "  'algorithms',\n",
       "  'learn',\n",
       "  'make',\n",
       "  'predictions',\n",
       "  'decisions',\n",
       "  'based',\n",
       "  'data',\n",
       "  '.',\n",
       "  'ML',\n",
       "  'algorithms',\n",
       "  'categorized',\n",
       "  'supervised',\n",
       "  'learning',\n",
       "  ',',\n",
       "  'unsupervised',\n",
       "  'learning',\n",
       "  ',',\n",
       "  'reinforcement',\n",
       "  'learning',\n",
       "  ',',\n",
       "  'depending',\n",
       "  'type',\n",
       "  'training',\n",
       "  'data',\n",
       "  'learning',\n",
       "  'task',\n",
       "  '.',\n",
       "  'Supervised',\n",
       "  'learning',\n",
       "  'involves',\n",
       "  'training',\n",
       "  'model',\n",
       "  'labeled',\n",
       "  'data',\n",
       "  ',',\n",
       "  'unsupervised',\n",
       "  'learning',\n",
       "  'involves',\n",
       "  'training',\n",
       "  'unlabeled',\n",
       "  'data',\n",
       "  '.',\n",
       "  'Reinforcement',\n",
       "  'learning',\n",
       "  'involves',\n",
       "  'training',\n",
       "  'model',\n",
       "  'interact',\n",
       "  'environment',\n",
       "  'learn',\n",
       "  'feedback',\n",
       "  '.',\n",
       "  'ML',\n",
       "  'techniques',\n",
       "  'applications',\n",
       "  'various',\n",
       "  'domains',\n",
       "  ',',\n",
       "  'including',\n",
       "  'image',\n",
       "  'recognition',\n",
       "  ',',\n",
       "  'speech',\n",
       "  'recognition',\n",
       "  ',',\n",
       "  'medical',\n",
       "  'diagnosis',\n",
       "  ',',\n",
       "  'autonomous',\n",
       "  'vehicles',\n",
       "  '.'],\n",
       " ['#',\n",
       "  'Data',\n",
       "  'science',\n",
       "  'interdisciplinary',\n",
       "  'field',\n",
       "  'combines',\n",
       "  'techniques',\n",
       "  'statistics',\n",
       "  ',',\n",
       "  'computer',\n",
       "  'science',\n",
       "  ',',\n",
       "  'domain-specific',\n",
       "  'knowledge',\n",
       "  'extract',\n",
       "  'insights',\n",
       "  'knowledge',\n",
       "  'data',\n",
       "  '.',\n",
       "  'It',\n",
       "  'involves',\n",
       "  'various',\n",
       "  'stages',\n",
       "  'data',\n",
       "  'lifecycle',\n",
       "  ',',\n",
       "  'including',\n",
       "  'data',\n",
       "  'collection',\n",
       "  ',',\n",
       "  'data',\n",
       "  'cleaning',\n",
       "  ',',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  ',',\n",
       "  'data',\n",
       "  'visualization',\n",
       "  '.',\n",
       "  'Data',\n",
       "  'scientists',\n",
       "  'use',\n",
       "  'variety',\n",
       "  'tools',\n",
       "  'techniques',\n",
       "  ',',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  ',',\n",
       "  'statistical',\n",
       "  'modeling',\n",
       "  ',',\n",
       "  'data',\n",
       "  'mining',\n",
       "  ',',\n",
       "  'uncover',\n",
       "  'patterns',\n",
       "  'trends',\n",
       "  'data',\n",
       "  'make',\n",
       "  'data-driven',\n",
       "  'decisions',\n",
       "  '.',\n",
       "  'Data',\n",
       "  'science',\n",
       "  'applications',\n",
       "  'numerous',\n",
       "  'industries',\n",
       "  ',',\n",
       "  'including',\n",
       "  'healthcare',\n",
       "  ',',\n",
       "  'finance',\n",
       "  ',',\n",
       "  'marketing',\n",
       "  ',',\n",
       "  'e-commerce',\n",
       "  '.']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_tokens_without_stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7604c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_freq(doc_tokens):\n",
    "    term_frequiences = []\n",
    "    for doc in doc_tokens:\n",
    "        term_frequency = {}\n",
    "        for token in doc:\n",
    "            try:\n",
    "                term_frequency[token] += 1\n",
    "            except:\n",
    "                term_frequency[token] = 1\n",
    "        n = len(doc)\n",
    "        unique_tokens = set(doc)\n",
    "        for token in unique_tokens:\n",
    "            term_frequency[token] /= n\n",
    "        term_frequiences.append(term_frequency)\n",
    "    return term_frequiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ce05ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequency = get_term_freq(document_tokens_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "410fb359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Natural': 0.011111111111111112,\n",
       "  'language': 0.044444444444444446,\n",
       "  'processing': 0.011111111111111112,\n",
       "  '(': 0.011111111111111112,\n",
       "  'NLP': 0.044444444444444446,\n",
       "  ')': 0.011111111111111112,\n",
       "  'field': 0.011111111111111112,\n",
       "  'artificial': 0.011111111111111112,\n",
       "  'intelligence': 0.011111111111111112,\n",
       "  'concerned': 0.011111111111111112,\n",
       "  'interaction': 0.011111111111111112,\n",
       "  'computers': 0.03333333333333333,\n",
       "  'humans': 0.011111111111111112,\n",
       "  'natural': 0.022222222222222223,\n",
       "  '.': 0.05555555555555555,\n",
       "  'It': 0.011111111111111112,\n",
       "  'aims': 0.011111111111111112,\n",
       "  'enable': 0.011111111111111112,\n",
       "  'understand': 0.022222222222222223,\n",
       "  ',': 0.1,\n",
       "  'interpret': 0.011111111111111112,\n",
       "  'generate': 0.011111111111111112,\n",
       "  'human': 0.011111111111111112,\n",
       "  'way': 0.011111111111111112,\n",
       "  'meaningful': 0.011111111111111112,\n",
       "  'useful': 0.011111111111111112,\n",
       "  'techniques': 0.011111111111111112,\n",
       "  'used': 0.011111111111111112,\n",
       "  'wide': 0.011111111111111112,\n",
       "  'range': 0.011111111111111112,\n",
       "  'applications': 0.011111111111111112,\n",
       "  'including': 0.011111111111111112,\n",
       "  'machine': 0.022222222222222223,\n",
       "  'translation': 0.011111111111111112,\n",
       "  'sentiment': 0.011111111111111112,\n",
       "  'analysis': 0.011111111111111112,\n",
       "  'information': 0.011111111111111112,\n",
       "  'extraction': 0.011111111111111112,\n",
       "  'text': 0.022222222222222223,\n",
       "  'summarization': 0.011111111111111112,\n",
       "  'One': 0.011111111111111112,\n",
       "  'key': 0.011111111111111112,\n",
       "  'challenges': 0.011111111111111112,\n",
       "  'dealing': 0.011111111111111112,\n",
       "  'ambiguity': 0.011111111111111112,\n",
       "  'variability': 0.011111111111111112,\n",
       "  'make': 0.011111111111111112,\n",
       "  'difficult': 0.011111111111111112,\n",
       "  'accurately': 0.011111111111111112,\n",
       "  'process': 0.011111111111111112,\n",
       "  'However': 0.011111111111111112,\n",
       "  'recent': 0.011111111111111112,\n",
       "  'advances': 0.011111111111111112,\n",
       "  'learning': 0.022222222222222223,\n",
       "  'deep': 0.011111111111111112,\n",
       "  'led': 0.011111111111111112,\n",
       "  'significant': 0.011111111111111112,\n",
       "  'improvements': 0.011111111111111112,\n",
       "  'performance': 0.011111111111111112,\n",
       "  'making': 0.011111111111111112,\n",
       "  'increasingly': 0.011111111111111112,\n",
       "  'important': 0.011111111111111112,\n",
       "  'area': 0.011111111111111112,\n",
       "  'research': 0.011111111111111112,\n",
       "  'development': 0.011111111111111112},\n",
       " {'#': 0.012195121951219513,\n",
       "  'Machine': 0.012195121951219513,\n",
       "  'learning': 0.0975609756097561,\n",
       "  '(': 0.012195121951219513,\n",
       "  'ML': 0.036585365853658534,\n",
       "  ')': 0.012195121951219513,\n",
       "  'subset': 0.012195121951219513,\n",
       "  'artificial': 0.012195121951219513,\n",
       "  'intelligence': 0.012195121951219513,\n",
       "  'focuses': 0.012195121951219513,\n",
       "  'development': 0.012195121951219513,\n",
       "  'algorithms': 0.024390243902439025,\n",
       "  'learn': 0.024390243902439025,\n",
       "  'make': 0.012195121951219513,\n",
       "  'predictions': 0.012195121951219513,\n",
       "  'decisions': 0.012195121951219513,\n",
       "  'based': 0.012195121951219513,\n",
       "  'data': 0.04878048780487805,\n",
       "  '.': 0.06097560975609756,\n",
       "  'categorized': 0.012195121951219513,\n",
       "  'supervised': 0.012195121951219513,\n",
       "  ',': 0.0975609756097561,\n",
       "  'unsupervised': 0.024390243902439025,\n",
       "  'reinforcement': 0.012195121951219513,\n",
       "  'depending': 0.012195121951219513,\n",
       "  'type': 0.012195121951219513,\n",
       "  'training': 0.04878048780487805,\n",
       "  'task': 0.012195121951219513,\n",
       "  'Supervised': 0.012195121951219513,\n",
       "  'involves': 0.036585365853658534,\n",
       "  'model': 0.024390243902439025,\n",
       "  'labeled': 0.012195121951219513,\n",
       "  'unlabeled': 0.012195121951219513,\n",
       "  'Reinforcement': 0.012195121951219513,\n",
       "  'interact': 0.012195121951219513,\n",
       "  'environment': 0.012195121951219513,\n",
       "  'feedback': 0.012195121951219513,\n",
       "  'techniques': 0.012195121951219513,\n",
       "  'applications': 0.012195121951219513,\n",
       "  'various': 0.012195121951219513,\n",
       "  'domains': 0.012195121951219513,\n",
       "  'including': 0.012195121951219513,\n",
       "  'image': 0.012195121951219513,\n",
       "  'recognition': 0.024390243902439025,\n",
       "  'speech': 0.012195121951219513,\n",
       "  'medical': 0.012195121951219513,\n",
       "  'diagnosis': 0.012195121951219513,\n",
       "  'autonomous': 0.012195121951219513,\n",
       "  'vehicles': 0.012195121951219513},\n",
       " {'#': 0.01282051282051282,\n",
       "  'Data': 0.038461538461538464,\n",
       "  'science': 0.038461538461538464,\n",
       "  'interdisciplinary': 0.01282051282051282,\n",
       "  'field': 0.01282051282051282,\n",
       "  'combines': 0.01282051282051282,\n",
       "  'techniques': 0.02564102564102564,\n",
       "  'statistics': 0.01282051282051282,\n",
       "  ',': 0.1794871794871795,\n",
       "  'computer': 0.01282051282051282,\n",
       "  'domain-specific': 0.01282051282051282,\n",
       "  'knowledge': 0.02564102564102564,\n",
       "  'extract': 0.01282051282051282,\n",
       "  'insights': 0.01282051282051282,\n",
       "  'data': 0.10256410256410256,\n",
       "  '.': 0.05128205128205128,\n",
       "  'It': 0.01282051282051282,\n",
       "  'involves': 0.01282051282051282,\n",
       "  'various': 0.01282051282051282,\n",
       "  'stages': 0.01282051282051282,\n",
       "  'lifecycle': 0.01282051282051282,\n",
       "  'including': 0.02564102564102564,\n",
       "  'collection': 0.01282051282051282,\n",
       "  'cleaning': 0.01282051282051282,\n",
       "  'analysis': 0.01282051282051282,\n",
       "  'visualization': 0.01282051282051282,\n",
       "  'scientists': 0.01282051282051282,\n",
       "  'use': 0.01282051282051282,\n",
       "  'variety': 0.01282051282051282,\n",
       "  'tools': 0.01282051282051282,\n",
       "  'machine': 0.01282051282051282,\n",
       "  'learning': 0.01282051282051282,\n",
       "  'statistical': 0.01282051282051282,\n",
       "  'modeling': 0.01282051282051282,\n",
       "  'mining': 0.01282051282051282,\n",
       "  'uncover': 0.01282051282051282,\n",
       "  'patterns': 0.01282051282051282,\n",
       "  'trends': 0.01282051282051282,\n",
       "  'make': 0.01282051282051282,\n",
       "  'data-driven': 0.01282051282051282,\n",
       "  'decisions': 0.01282051282051282,\n",
       "  'applications': 0.01282051282051282,\n",
       "  'numerous': 0.01282051282051282,\n",
       "  'industries': 0.01282051282051282,\n",
       "  'healthcare': 0.01282051282051282,\n",
       "  'finance': 0.01282051282051282,\n",
       "  'marketing': 0.01282051282051282,\n",
       "  'e-commerce': 0.01282051282051282}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2d433ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inverse_doc_frequency(term_frequency):\n",
    "    document_cnt = len(term_frequency)\n",
    "    inverse_doc_frequencies = []\n",
    "    for doc in term_frequency:\n",
    "        tokens = list(doc.keys())\n",
    "        inverse_doc_frequency = {}\n",
    "        for token in tokens:\n",
    "            doc_freq = 1 \n",
    "            for doc in term_frequency:\n",
    "                if (token in doc.keys()):\n",
    "                    doc_freq += 1\n",
    "            inverse_doc_frequency[token] = math.log(document_cnt/doc_freq)\n",
    "        inverse_doc_frequencies.append(inverse_doc_frequency)\n",
    "    return inverse_doc_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bbbea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_doc_frequency = get_inverse_doc_frequency(term_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6be3c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Natural': 0.4054651081081644,\n",
       "  'language': 0.4054651081081644,\n",
       "  'processing': 0.4054651081081644,\n",
       "  '(': 0.0,\n",
       "  'NLP': 0.4054651081081644,\n",
       "  ')': 0.0,\n",
       "  'field': 0.0,\n",
       "  'artificial': 0.0,\n",
       "  'intelligence': 0.0,\n",
       "  'concerned': 0.4054651081081644,\n",
       "  'interaction': 0.4054651081081644,\n",
       "  'computers': 0.4054651081081644,\n",
       "  'humans': 0.4054651081081644,\n",
       "  'natural': 0.4054651081081644,\n",
       "  '.': -0.2876820724517809,\n",
       "  'It': 0.0,\n",
       "  'aims': 0.4054651081081644,\n",
       "  'enable': 0.4054651081081644,\n",
       "  'understand': 0.4054651081081644,\n",
       "  ',': -0.2876820724517809,\n",
       "  'interpret': 0.4054651081081644,\n",
       "  'generate': 0.4054651081081644,\n",
       "  'human': 0.4054651081081644,\n",
       "  'way': 0.4054651081081644,\n",
       "  'meaningful': 0.4054651081081644,\n",
       "  'useful': 0.4054651081081644,\n",
       "  'techniques': -0.2876820724517809,\n",
       "  'used': 0.4054651081081644,\n",
       "  'wide': 0.4054651081081644,\n",
       "  'range': 0.4054651081081644,\n",
       "  'applications': -0.2876820724517809,\n",
       "  'including': -0.2876820724517809,\n",
       "  'machine': 0.0,\n",
       "  'translation': 0.4054651081081644,\n",
       "  'sentiment': 0.4054651081081644,\n",
       "  'analysis': 0.0,\n",
       "  'information': 0.4054651081081644,\n",
       "  'extraction': 0.4054651081081644,\n",
       "  'text': 0.4054651081081644,\n",
       "  'summarization': 0.4054651081081644,\n",
       "  'One': 0.4054651081081644,\n",
       "  'key': 0.4054651081081644,\n",
       "  'challenges': 0.4054651081081644,\n",
       "  'dealing': 0.4054651081081644,\n",
       "  'ambiguity': 0.4054651081081644,\n",
       "  'variability': 0.4054651081081644,\n",
       "  'make': -0.2876820724517809,\n",
       "  'difficult': 0.4054651081081644,\n",
       "  'accurately': 0.4054651081081644,\n",
       "  'process': 0.4054651081081644,\n",
       "  'However': 0.4054651081081644,\n",
       "  'recent': 0.4054651081081644,\n",
       "  'advances': 0.4054651081081644,\n",
       "  'learning': -0.2876820724517809,\n",
       "  'deep': 0.4054651081081644,\n",
       "  'led': 0.4054651081081644,\n",
       "  'significant': 0.4054651081081644,\n",
       "  'improvements': 0.4054651081081644,\n",
       "  'performance': 0.4054651081081644,\n",
       "  'making': 0.4054651081081644,\n",
       "  'increasingly': 0.4054651081081644,\n",
       "  'important': 0.4054651081081644,\n",
       "  'area': 0.4054651081081644,\n",
       "  'research': 0.4054651081081644,\n",
       "  'development': 0.0},\n",
       " {'#': 0.0,\n",
       "  'Machine': 0.4054651081081644,\n",
       "  'learning': -0.2876820724517809,\n",
       "  '(': 0.0,\n",
       "  'ML': 0.4054651081081644,\n",
       "  ')': 0.0,\n",
       "  'subset': 0.4054651081081644,\n",
       "  'artificial': 0.0,\n",
       "  'intelligence': 0.0,\n",
       "  'focuses': 0.4054651081081644,\n",
       "  'development': 0.0,\n",
       "  'algorithms': 0.4054651081081644,\n",
       "  'learn': 0.4054651081081644,\n",
       "  'make': -0.2876820724517809,\n",
       "  'predictions': 0.4054651081081644,\n",
       "  'decisions': 0.0,\n",
       "  'based': 0.4054651081081644,\n",
       "  'data': 0.0,\n",
       "  '.': -0.2876820724517809,\n",
       "  'categorized': 0.4054651081081644,\n",
       "  'supervised': 0.4054651081081644,\n",
       "  ',': -0.2876820724517809,\n",
       "  'unsupervised': 0.4054651081081644,\n",
       "  'reinforcement': 0.4054651081081644,\n",
       "  'depending': 0.4054651081081644,\n",
       "  'type': 0.4054651081081644,\n",
       "  'training': 0.4054651081081644,\n",
       "  'task': 0.4054651081081644,\n",
       "  'Supervised': 0.4054651081081644,\n",
       "  'involves': 0.0,\n",
       "  'model': 0.4054651081081644,\n",
       "  'labeled': 0.4054651081081644,\n",
       "  'unlabeled': 0.4054651081081644,\n",
       "  'Reinforcement': 0.4054651081081644,\n",
       "  'interact': 0.4054651081081644,\n",
       "  'environment': 0.4054651081081644,\n",
       "  'feedback': 0.4054651081081644,\n",
       "  'techniques': -0.2876820724517809,\n",
       "  'applications': -0.2876820724517809,\n",
       "  'various': 0.0,\n",
       "  'domains': 0.4054651081081644,\n",
       "  'including': -0.2876820724517809,\n",
       "  'image': 0.4054651081081644,\n",
       "  'recognition': 0.4054651081081644,\n",
       "  'speech': 0.4054651081081644,\n",
       "  'medical': 0.4054651081081644,\n",
       "  'diagnosis': 0.4054651081081644,\n",
       "  'autonomous': 0.4054651081081644,\n",
       "  'vehicles': 0.4054651081081644},\n",
       " {'#': 0.0,\n",
       "  'Data': 0.4054651081081644,\n",
       "  'science': 0.4054651081081644,\n",
       "  'interdisciplinary': 0.4054651081081644,\n",
       "  'field': 0.0,\n",
       "  'combines': 0.4054651081081644,\n",
       "  'techniques': -0.2876820724517809,\n",
       "  'statistics': 0.4054651081081644,\n",
       "  ',': -0.2876820724517809,\n",
       "  'computer': 0.4054651081081644,\n",
       "  'domain-specific': 0.4054651081081644,\n",
       "  'knowledge': 0.4054651081081644,\n",
       "  'extract': 0.4054651081081644,\n",
       "  'insights': 0.4054651081081644,\n",
       "  'data': 0.0,\n",
       "  '.': -0.2876820724517809,\n",
       "  'It': 0.0,\n",
       "  'involves': 0.0,\n",
       "  'various': 0.0,\n",
       "  'stages': 0.4054651081081644,\n",
       "  'lifecycle': 0.4054651081081644,\n",
       "  'including': -0.2876820724517809,\n",
       "  'collection': 0.4054651081081644,\n",
       "  'cleaning': 0.4054651081081644,\n",
       "  'analysis': 0.0,\n",
       "  'visualization': 0.4054651081081644,\n",
       "  'scientists': 0.4054651081081644,\n",
       "  'use': 0.4054651081081644,\n",
       "  'variety': 0.4054651081081644,\n",
       "  'tools': 0.4054651081081644,\n",
       "  'machine': 0.0,\n",
       "  'learning': -0.2876820724517809,\n",
       "  'statistical': 0.4054651081081644,\n",
       "  'modeling': 0.4054651081081644,\n",
       "  'mining': 0.4054651081081644,\n",
       "  'uncover': 0.4054651081081644,\n",
       "  'patterns': 0.4054651081081644,\n",
       "  'trends': 0.4054651081081644,\n",
       "  'make': -0.2876820724517809,\n",
       "  'data-driven': 0.4054651081081644,\n",
       "  'decisions': 0.0,\n",
       "  'applications': -0.2876820724517809,\n",
       "  'numerous': 0.4054651081081644,\n",
       "  'industries': 0.4054651081081644,\n",
       "  'healthcare': 0.4054651081081644,\n",
       "  'finance': 0.4054651081081644,\n",
       "  'marketing': 0.4054651081081644,\n",
       "  'e-commerce': 0.4054651081081644}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_doc_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35290a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(term_frequency,inverse_doc_frequency):\n",
    "    n = len(term_frequency)\n",
    "    tf_idfs = []\n",
    "    for i in range(n):\n",
    "        tokens = list(term_frequency[i].keys())\n",
    "        tf_idf = {}\n",
    "        for token in tokens:\n",
    "            tf_idf[token] = term_frequency[i][token] * inverse_doc_frequency[i][token]\n",
    "        tf_idfs.append(tf_idf)\n",
    "    return tf_idfs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f817bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = get_tf_idf(term_frequency,inverse_doc_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dba6801d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Natural': 0.004505167867868493,\n",
       "  'language': 0.018020671471473973,\n",
       "  'processing': 0.004505167867868493,\n",
       "  '(': 0.0,\n",
       "  'NLP': 0.018020671471473973,\n",
       "  ')': 0.0,\n",
       "  'field': 0.0,\n",
       "  'artificial': 0.0,\n",
       "  'intelligence': 0.0,\n",
       "  'concerned': 0.004505167867868493,\n",
       "  'interaction': 0.004505167867868493,\n",
       "  'computers': 0.01351550360360548,\n",
       "  'humans': 0.004505167867868493,\n",
       "  'natural': 0.009010335735736986,\n",
       "  '.': -0.015982337358432273,\n",
       "  'It': 0.0,\n",
       "  'aims': 0.004505167867868493,\n",
       "  'enable': 0.004505167867868493,\n",
       "  'understand': 0.009010335735736986,\n",
       "  ',': -0.02876820724517809,\n",
       "  'interpret': 0.004505167867868493,\n",
       "  'generate': 0.004505167867868493,\n",
       "  'human': 0.004505167867868493,\n",
       "  'way': 0.004505167867868493,\n",
       "  'meaningful': 0.004505167867868493,\n",
       "  'useful': 0.004505167867868493,\n",
       "  'techniques': -0.003196467471686455,\n",
       "  'used': 0.004505167867868493,\n",
       "  'wide': 0.004505167867868493,\n",
       "  'range': 0.004505167867868493,\n",
       "  'applications': -0.003196467471686455,\n",
       "  'including': -0.003196467471686455,\n",
       "  'machine': 0.0,\n",
       "  'translation': 0.004505167867868493,\n",
       "  'sentiment': 0.004505167867868493,\n",
       "  'analysis': 0.0,\n",
       "  'information': 0.004505167867868493,\n",
       "  'extraction': 0.004505167867868493,\n",
       "  'text': 0.009010335735736986,\n",
       "  'summarization': 0.004505167867868493,\n",
       "  'One': 0.004505167867868493,\n",
       "  'key': 0.004505167867868493,\n",
       "  'challenges': 0.004505167867868493,\n",
       "  'dealing': 0.004505167867868493,\n",
       "  'ambiguity': 0.004505167867868493,\n",
       "  'variability': 0.004505167867868493,\n",
       "  'make': -0.003196467471686455,\n",
       "  'difficult': 0.004505167867868493,\n",
       "  'accurately': 0.004505167867868493,\n",
       "  'process': 0.004505167867868493,\n",
       "  'However': 0.004505167867868493,\n",
       "  'recent': 0.004505167867868493,\n",
       "  'advances': 0.004505167867868493,\n",
       "  'learning': -0.00639293494337291,\n",
       "  'deep': 0.004505167867868493,\n",
       "  'led': 0.004505167867868493,\n",
       "  'significant': 0.004505167867868493,\n",
       "  'improvements': 0.004505167867868493,\n",
       "  'performance': 0.004505167867868493,\n",
       "  'making': 0.004505167867868493,\n",
       "  'increasingly': 0.004505167867868493,\n",
       "  'important': 0.004505167867868493,\n",
       "  'area': 0.004505167867868493,\n",
       "  'research': 0.004505167867868493,\n",
       "  'development': 0.0},\n",
       " {'#': 0.0,\n",
       "  'Machine': 0.0049446964403434684,\n",
       "  'learning': -0.028066543653832283,\n",
       "  '(': 0.0,\n",
       "  'ML': 0.014834089321030404,\n",
       "  ')': 0.0,\n",
       "  'subset': 0.0049446964403434684,\n",
       "  'artificial': 0.0,\n",
       "  'intelligence': 0.0,\n",
       "  'focuses': 0.0049446964403434684,\n",
       "  'development': 0.0,\n",
       "  'algorithms': 0.009889392880686937,\n",
       "  'learn': 0.009889392880686937,\n",
       "  'make': -0.0035083179567290354,\n",
       "  'predictions': 0.0049446964403434684,\n",
       "  'decisions': 0.0,\n",
       "  'based': 0.0049446964403434684,\n",
       "  'data': 0.0,\n",
       "  '.': -0.017541589783645176,\n",
       "  'categorized': 0.0049446964403434684,\n",
       "  'supervised': 0.0049446964403434684,\n",
       "  ',': -0.028066543653832283,\n",
       "  'unsupervised': 0.009889392880686937,\n",
       "  'reinforcement': 0.0049446964403434684,\n",
       "  'depending': 0.0049446964403434684,\n",
       "  'type': 0.0049446964403434684,\n",
       "  'training': 0.019778785761373874,\n",
       "  'task': 0.0049446964403434684,\n",
       "  'Supervised': 0.0049446964403434684,\n",
       "  'involves': 0.0,\n",
       "  'model': 0.009889392880686937,\n",
       "  'labeled': 0.0049446964403434684,\n",
       "  'unlabeled': 0.0049446964403434684,\n",
       "  'Reinforcement': 0.0049446964403434684,\n",
       "  'interact': 0.0049446964403434684,\n",
       "  'environment': 0.0049446964403434684,\n",
       "  'feedback': 0.0049446964403434684,\n",
       "  'techniques': -0.0035083179567290354,\n",
       "  'applications': -0.0035083179567290354,\n",
       "  'various': 0.0,\n",
       "  'domains': 0.0049446964403434684,\n",
       "  'including': -0.0035083179567290354,\n",
       "  'image': 0.0049446964403434684,\n",
       "  'recognition': 0.009889392880686937,\n",
       "  'speech': 0.0049446964403434684,\n",
       "  'medical': 0.0049446964403434684,\n",
       "  'diagnosis': 0.0049446964403434684,\n",
       "  'autonomous': 0.0049446964403434684,\n",
       "  'vehicles': 0.0049446964403434684},\n",
       " {'#': 0.0,\n",
       "  'Data': 0.015594811850314015,\n",
       "  'science': 0.015594811850314015,\n",
       "  'interdisciplinary': 0.0051982706167713385,\n",
       "  'field': 0.0,\n",
       "  'combines': 0.0051982706167713385,\n",
       "  'techniques': -0.00737646339619951,\n",
       "  'statistics': 0.0051982706167713385,\n",
       "  ',': -0.05163524377339657,\n",
       "  'computer': 0.0051982706167713385,\n",
       "  'domain-specific': 0.0051982706167713385,\n",
       "  'knowledge': 0.010396541233542677,\n",
       "  'extract': 0.0051982706167713385,\n",
       "  'insights': 0.0051982706167713385,\n",
       "  'data': 0.0,\n",
       "  '.': -0.01475292679239902,\n",
       "  'It': 0.0,\n",
       "  'involves': 0.0,\n",
       "  'various': 0.0,\n",
       "  'stages': 0.0051982706167713385,\n",
       "  'lifecycle': 0.0051982706167713385,\n",
       "  'including': -0.00737646339619951,\n",
       "  'collection': 0.0051982706167713385,\n",
       "  'cleaning': 0.0051982706167713385,\n",
       "  'analysis': 0.0,\n",
       "  'visualization': 0.0051982706167713385,\n",
       "  'scientists': 0.0051982706167713385,\n",
       "  'use': 0.0051982706167713385,\n",
       "  'variety': 0.0051982706167713385,\n",
       "  'tools': 0.0051982706167713385,\n",
       "  'machine': 0.0,\n",
       "  'learning': -0.003688231698099755,\n",
       "  'statistical': 0.0051982706167713385,\n",
       "  'modeling': 0.0051982706167713385,\n",
       "  'mining': 0.0051982706167713385,\n",
       "  'uncover': 0.0051982706167713385,\n",
       "  'patterns': 0.0051982706167713385,\n",
       "  'trends': 0.0051982706167713385,\n",
       "  'make': -0.003688231698099755,\n",
       "  'data-driven': 0.0051982706167713385,\n",
       "  'decisions': 0.0,\n",
       "  'applications': -0.003688231698099755,\n",
       "  'numerous': 0.0051982706167713385,\n",
       "  'industries': 0.0051982706167713385,\n",
       "  'healthcare': 0.0051982706167713385,\n",
       "  'finance': 0.0051982706167713385,\n",
       "  'marketing': 0.0051982706167713385,\n",
       "  'e-commerce': 0.0051982706167713385}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdceb320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
